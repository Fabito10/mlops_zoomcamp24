{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3d2796-7ff8-4a2a-88d0-77b4237ba878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/ubuntu/anaconda3/lib/python3.11/site-packages (14.0.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/ubuntu/anaconda3/lib/python3.11/site-packages (from pyarrow) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61ca133-9612-4d43-84fa-77bfa0c668be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c0b363-2e46-40a3-baca-f817da9bb9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in January data: 19\n",
      "Standard deviation of trip duration in January: 42.59\n",
      "Fraction of records remaining after filtering outliers: 98.12%\n",
      "Dimensionality of the feature matrix: 515\n",
      "RMSE on training data: 7.65\n",
      "RMSE on validation data: 13.32\n"
     ]
    }
   ],
   "source": [
    "def download_data(url, filename):\n",
    "    df = pd.read_parquet(url)\n",
    "    df.to_parquet(filename)\n",
    "    return df\n",
    "\n",
    "def load_data(filename):\n",
    "    return pd.read_parquet(filename)\n",
    "\n",
    "def compute_duration(df):\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    return df\n",
    "\n",
    "def filter_outliers(df, min_duration=1, max_duration=60):\n",
    "    return df[(df['duration'] >= min_duration) & (df['duration'] <= max_duration)]\n",
    "\n",
    "def one_hot_encode(df, columns):\n",
    "    df.loc[:, columns] = df[columns].astype(str)  # Use .loc to avoid SettingWithCopyWarning\n",
    "    data_dicts = df[columns].to_dict(orient='records')\n",
    "    dv = DictVectorizer()\n",
    "    X = dv.fit_transform(data_dicts)\n",
    "    return X, dv\n",
    "\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def calculate_rmse(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return rmse\n",
    "\n",
    "def main():\n",
    "    # URLs for the datasets\n",
    "    url_january = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "    url_february = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\"\n",
    "\n",
    "    # Filenames for local storage\n",
    "    filename_january = \"./data/yellow_tripdata_2023-01.parquet\"\n",
    "    filename_february = \"./data/yellow_tripdata_2023-02.parquet\"\n",
    "\n",
    "    # Download and load the data\n",
    "    df_january = download_data(url_january, filename_january)\n",
    "    df_february = download_data(url_february, filename_february)\n",
    "\n",
    "    # Question 1\n",
    "    num_columns_january = df_january.shape[1]\n",
    "    print(f\"Number of columns in January data: {num_columns_january}\")\n",
    "\n",
    "    # Question 2\n",
    "    df_january = compute_duration(df_january)\n",
    "    std_duration = df_january['duration'].std()\n",
    "    print(f\"Standard deviation of trip duration in January: {std_duration:.2f}\")\n",
    "\n",
    "    # Question 3\n",
    "    df_january_filtered = filter_outliers(df_january)\n",
    "    fraction_remaining = len(df_january_filtered) / len(df_january)\n",
    "    print(f\"Fraction of records remaining after filtering outliers: {fraction_remaining:.2%}\")\n",
    "\n",
    "    # Question 4\n",
    "    columns_to_encode = ['PULocationID', 'DOLocationID']\n",
    "    X_january, dv = one_hot_encode(df_january_filtered, columns_to_encode)\n",
    "    dimensionality = X_january.shape[1]\n",
    "    print(f\"Dimensionality of the feature matrix: {dimensionality}\")\n",
    "\n",
    "    # Question 5\n",
    "    y_january = df_january_filtered['duration'].values\n",
    "    model = train_model(X_january, y_january)\n",
    "    rmse_train = calculate_rmse(model, X_january, y_january)\n",
    "    print(f\"RMSE on training data: {rmse_train:.2f}\")\n",
    "\n",
    "    # Question 6\n",
    "    df_february = compute_duration(df_february)\n",
    "    df_february_filtered = filter_outliers(df_february)\n",
    "    X_february = dv.transform(df_february_filtered[columns_to_encode].to_dict(orient='records'))\n",
    "    y_february = df_february_filtered['duration'].values\n",
    "    rmse_val = calculate_rmse(model, X_february, y_february)\n",
    "    print(f\"RMSE on validation data: {rmse_val:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9779c49-6c88-4c7a-a6b2-6fc024acfec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfad3f4-6e0a-4423-a070-b50857288b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
